{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6480e9ea",
   "metadata": {},
   "source": [
    "# Jared Godar Regression Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f641c",
   "metadata": {},
   "source": [
    "This is the overall working notebook used to acquire / prepare / clean / scale / and explore my zillo data.\n",
    "\n",
    "The modeling and evaluation portion will be in a second notebook `zillo-modeling.ipynb`\n",
    "\n",
    "Streamlined highlights from both notebooks can be found in the `zillo-report.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e1dca4",
   "metadata": {},
   "source": [
    "Import libraries used in project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8e25a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "#Vizualization Tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Modeling Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from datetime import date\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "## Evaluation tools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Custim functions\n",
    "from env import host, user, password #Database credentials\n",
    "import zillo_wrangle\n",
    "import z_wrangle2\n",
    "import z_wrangle3\n",
    "import eval_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ceaa0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aff8bb",
   "metadata": {},
   "source": [
    "## Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "83c61d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to contact database\n",
    "def get_db_url(db_name):\n",
    "    return f\"mysql+pymysql://{user}:{password}@{host}/{db_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1fa37",
   "metadata": {},
   "source": [
    "- Look at zillow data dictionary. \n",
    "- Import minimum features (beds, bath, tax, year, fips)\n",
    "- See what other columns may prove useful in model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34765b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_excel('zillow_data_dictionary.xlsx')\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28902634",
   "metadata": {},
   "source": [
    "### Takeaways: Columns of interest that may have predictive value\n",
    "\n",
    "- `buildingqualitytypeid` Quality \n",
    "- `fireplacecnt`\n",
    "- `garagecarcnt`\n",
    "- `poolcnt`\n",
    "- `rawcensustractandblock`\n",
    "- `censustractandblock`\n",
    "- `regionidzip`\n",
    "- `regionidneighborhood`\n",
    "- `storytypeid`\n",
    "\n",
    "\n",
    "import:\n",
    "- `regionidcounty`\n",
    "- \n",
    "- `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e0600",
   "metadata": {},
   "source": [
    "Use SQL query to get single unit (`propertylandusetypeid=261`) from May-Aug, 2017 filtering for non-zero values to have fewer nulls in the first data pull to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ba884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_sql():\n",
    "    query = \"\"\"\n",
    "    SELECT bedroomcnt as bedrooms, \n",
    "       bathroomcnt as bathrooms,\n",
    "       calculatedfinishedsquarefeet as square_feet,\n",
    "       yearbuilt as year,\n",
    "       taxamount as taxes,\n",
    "       taxvaluedollarcnt as home_value,\n",
    "       fips as fips,\n",
    "       regionidzip as zip_code\n",
    "    FROM predictions_2017\n",
    "     JOIN properties_2017 USING(parcelid)\n",
    "    WHERE (transactiondate >= '2017-01-01' AND transactiondate <= '2017-12-31') \n",
    "        AND propertylandusetypeid = '261'\n",
    "        AND bedroomcnt > 0\n",
    "        AND bathroomcnt > 0\n",
    "        AND calculatedfinishedsquarefeet > 0 \n",
    "        AND taxamount > 0\n",
    "        AND taxvaluedollarcnt > 0\n",
    "        AND fips > 0\n",
    "    ORDER BY fips;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, get_db_url('zillow'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = get_data_from_sql()\n",
    "zillow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1 = zillow.shape\n",
    "shape1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5142faf",
   "metadata": {},
   "source": [
    "Count nulls by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.info(null_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total of null values for each row\n",
    "null1 = zillow.isnull().sum()\n",
    "null1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685af47",
   "metadata": {},
   "source": [
    "Lots of missing neighborhood data... Drop that column before filtering NAs. (Actually removed this field from the SQL query - now not imported and not dropped)\n",
    "\n",
    "- [ ] Drop city as well\n",
    "- [ ] Figure out how to get that information from `fips`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b008706",
   "metadata": {},
   "source": [
    "GO back to mysql workbench and see how many properties have the `single residential inferred` code 279\n",
    "\n",
    "- 55614 for single family\n",
    "\n",
    "- 0 records for inferred single family, so no need to include it in query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89b17a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1002d5",
   "metadata": {},
   "source": [
    "### Vizualize distribution and outliers\n",
    "\n",
    "- Eliminating outliers may also reduce the null value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b782e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "cols = [col for col in zillow.columns if col not in ['fips', 'year_built', 'zip_code', 'propertylandusedesc']]\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    zillow[col].hist(bins=5)\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # turn off scientific notation\n",
    "    #plt.ticklabel_format(useOffset=False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02204a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.ticklabel_format(useOffset=False, style='plain')\n",
    "sns.boxplot(data=zillow.drop(columns=['fips']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8431d17",
   "metadata": {},
   "source": [
    "Lots of outliers - especially in value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5175d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.describe().apply(lambda s: s.apply(lambda x: format(x, 'g')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3e70d",
   "metadata": {},
   "source": [
    "### Remove outliers\n",
    "\n",
    "Make remove outliers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23898e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, k, col_list):\n",
    "    ''' remove outliers specified columns in a dataframe given a user-enterd cutoff value\n",
    "    '''\n",
    "    \n",
    "    for col in col_list:\n",
    "\n",
    "        q1, q3 = df[col].quantile([.25, .75])  # get quartiles\n",
    "        \n",
    "        iqr = q3 - q1   # calculate interquartile range\n",
    "        \n",
    "        upper_bound = q3 + k * iqr   # get upper bound\n",
    "        lower_bound = q1 - k * iqr   # get lower bound\n",
    "\n",
    "        # return dataframe without outliers\n",
    "        \n",
    "        df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ad1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b421ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = remove_outliers(zillow, 1.5, ['bedrooms', 'bathrooms', 'square_feet', 'taxes', 'home_value'])\n",
    "zillow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape2 = zillow.shape\n",
    "print(shape1)\n",
    "print(shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146aa4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed1 = shape1[0]-shape2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6caa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original records: {shape1[0]}')\n",
    "print(f'Records Removed: {removed1}')\n",
    "print(f'Records remaining: {shape2[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d53fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total of null values for each row\n",
    "null2 = zillow.isnull().sum()\n",
    "print(null1)\n",
    "print(null2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b7a91",
   "metadata": {},
   "source": [
    "Reasonable number of null values copared to total records, go ahead and drop NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "zillow = zillow.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92bb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape3=zillow.shape\n",
    "shape3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4655d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed2=shape2[0]-shape3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33bb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original records: {shape2[0]}')\n",
    "print(f'Records Removed: {removed2}')\n",
    "print(f'Records remaining: {shape3[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cd527",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676866b0",
   "metadata": {},
   "source": [
    "### Vizualize distributions again minus outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "cols = [col for col in zillow.columns if col not in ['fips', 'zip_code', 'propertylandusedesc']]\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display histogram for column.\n",
    "    zillow[col].hist(bins=5)\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # turn off scientific notation\n",
    "    #plt.ticklabel_format(useOffset=False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc29671",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.ticklabel_format(useOffset=False, style='plain')\n",
    "sns.boxplot(data=zillow.drop(columns=['fips', 'zip_code']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5df612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns\n",
    "cols = [col for col in zillow.columns if col not in ['fips','zip_code', 'propertylandusedesc']]\n",
    "plt.figure(figsize=(16, 20))\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display boxplot for column.\n",
    "    sns.boxplot(data=zillow[col])\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ed4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adddb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns\n",
    "cols = ['bedrooms', 'bathrooms', 'square_feet', 'home_value', 'taxes']\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "\n",
    "    # i starts at 0, but plot should start at 1\n",
    "    plot_number = i + 1 \n",
    "\n",
    "    # Create subplot.\n",
    "    plt.subplot(1, len(cols), plot_number)\n",
    "\n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "\n",
    "    # Display boxplot for column.\n",
    "    sns.boxplot(data=zillow[[col]])\n",
    "\n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)\n",
    "\n",
    "    # sets proper spacing between plots\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48779c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean up my zillow df\n",
    "def clean_data(df):\n",
    "    '''\n",
    "    This funciton takes in the zillow df and drops observations with Null values\n",
    "    and handles data types returning a df with a basic clean.\n",
    "    '''\n",
    "    df = df.dropna()\n",
    "    df['fips'] = df['fips'].astype(int)\n",
    "    df['zip_code'] = df['zip_code'].astype(int)\n",
    "    df['square_feet'] = df['square_feet'].astype(int)\n",
    "    df['year'] = df['year'].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8266ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = clean_data(zillow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = clean_data(zillow)\n",
    "print(zillow.shape)\n",
    "zillow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32119960",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf66ec",
   "metadata": {},
   "source": [
    "### To Do in successve iterations beyond MVP\n",
    "\n",
    "- [ ] (for unchecked checkbox)\n",
    "- [x] (for checked checkbox)\n",
    "\n",
    "\n",
    "- [ ] Add column for range...\n",
    "- [ ] Import additional columns of potential use\n",
    "- [ ] Derive columns from there\n",
    "    - Pool (boolean)\n",
    "    - Condition (bins)\n",
    "    - Calculate age in years\n",
    "    - Bin ages\n",
    "    - Etc.\n",
    "- [ ] Lookup / populate county based on `fips`\n",
    "- [ ] Caculate tax rate percent (`taxes`, `home_value`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0365ce",
   "metadata": {},
   "source": [
    "-[] Add \"inferred single family residential\" code to original SQL query (not necessary, 0 records)\n",
    "\n",
    "- [x] left join on propertylandusetype\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea1478",
   "metadata": {},
   "source": [
    "Minor, but kind of annoying find out why `[ ]` is not rendering as a checkbox in markdown in VS Code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ddeafa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931bd42",
   "metadata": {},
   "source": [
    "## County Data for Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23fcd8",
   "metadata": {},
   "source": [
    "Fips codes can be found [here](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27e397",
   "metadata": {},
   "source": [
    "What fips are used in dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8886781",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.fips.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b60ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "29295+11806+3821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d360ae6",
   "metadata": {},
   "source": [
    "### Fips values \n",
    "\n",
    "| fips |   County    | State |\n",
    "| :--: | :---------: | :---: |\n",
    "| 6037 | Los Angeles |  CA   |\n",
    "| 6059 |   Orange    |  CA   |\n",
    "| 6111 |   Ventura   |  CA   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddd0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to add county based on fips by row\n",
    "\n",
    "def assign_county(row):\n",
    "    if row['fips']==6037:\n",
    "        return 'Los Angeles'\n",
    "    if row['fips']==6059:\n",
    "        return 'Orange'\n",
    "    if row['fips']==6111:\n",
    "        return 'Ventura'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4833e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use function to assign county\n",
    "\n",
    "zillow['county'] = zillow.apply(lambda row: assign_county(row), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a050d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add state columns\n",
    "\n",
    "zillow['state'] = 'CA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe97b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COnvert year into integer (May delete or comment out later since I added this to an earlier function)\n",
    "\n",
    "zillow['year'] = zillow['year'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a083a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confrim year dtype changed\n",
    "\n",
    "zillow.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ccd1a",
   "metadata": {},
   "source": [
    "### Add county averages to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 3 county dataframes\n",
    "\n",
    "la = zillow[zillow.county=='Los Angeles']\n",
    "oc = zillow[zillow.county=='Orange']\n",
    "ven = zillow[zillow.county=='Ventura']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average home price by county\n",
    "\n",
    "la_avg = la.home_value.mean()\n",
    "oc_avg = oc.home_value.mean()\n",
    "ven_avg = ven.home_value.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8070f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add average county price as column\n",
    "\n",
    "def assign_county_avg(row):\n",
    "    if row['fips']==6037:\n",
    "        return la_avg\n",
    "    if row['fips']==6059:\n",
    "        return oc_avg\n",
    "    if row['fips']==6111:\n",
    "        return ven_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow['county_avg'] = zillow.apply(lambda row: assign_county_avg(row), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d980339",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17d773",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d02ff2",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "- Will explore more later, but any initial features?\n",
    "- Transform year built to age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5303da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add age column\n",
    "zillow['age'] = date.today().year-zillow.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844779fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm\n",
    "\n",
    "zillow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2dc02",
   "metadata": {},
   "source": [
    "## Location Data\n",
    "\n",
    "- One-hot encode county so I can pass that to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to clean module\n",
    "\n",
    "dummy_df = pd.get_dummies(zillow[['county']], drop_first=True)\n",
    "zillow = pd.concat([zillow, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e319b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3217cc",
   "metadata": {},
   "source": [
    "### Add Tax rate column\n",
    "\n",
    "taxes = home_value * tax_rate\n",
    "\n",
    "tax_rate = taxes / home_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3beb2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow['tax_rate']=round(((zillow.taxes/zillow.home_value)*100),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffba1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.tax_rate.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow.tax_rate.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2869f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fad0e",
   "metadata": {},
   "source": [
    "## Split data into train, test, validate; Then create separate x/y feature/target dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_my_data(df, pct=0.10):\n",
    "    '''\n",
    "    This splits a dataframe into train, validate, and test sets. \n",
    "    df = dataframe to split\n",
    "    pct = size of the test set, 1/2 of size of the validate set\n",
    "    Returns three dataframes (train, validate, test)\n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=pct, random_state = 123)\n",
    "    train, validate = train_test_split(train_validate, test_size=pct*2, random_state = 123)\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_my_data(zillow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02259233",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf66ee",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "- Can go ahead and add a baseline, y_hat prediction\n",
    "- Will use the training median as baseline, less sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline\n",
    "\n",
    "baseline = train.home_value.median()\n",
    "baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d760589",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline'] = baseline\n",
    "validate['baseline'] = baseline\n",
    "test['baseline'] = baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into x / y | features / target\n",
    "\n",
    "# Setup X and y\n",
    "X_train = train.drop(columns='home_value')\n",
    "y_train = train.home_value\n",
    "\n",
    "X_validate = validate.drop(columns='home_value')\n",
    "y_validate = validate.home_value\n",
    "\n",
    "X_test = test.drop(columns='home_value')\n",
    "y_test = test.home_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902bacd0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37040182",
   "metadata": {},
   "source": [
    "## Data has been aquired and cleaned, now scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9133e3",
   "metadata": {},
   "source": [
    "Since even our cleaned data has a fair number of outliers still, I will use the robust scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e7e0d",
   "metadata": {},
   "source": [
    "### Beginning exploration\n",
    "\n",
    "- Examine pairwaise relationships\n",
    "    - Crosstabs\n",
    "    - Corr plots\n",
    "    - Pair plots\n",
    "    - Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84187b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b64d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb93fc",
   "metadata": {},
   "source": [
    "**NOTE:** I originally scaled `fips` and `zip_code` because I wanted to pass more granular location data to my model. However, using a scaled value imploes a numberic relationship between the values (90210 being 100 more somethings from 90110, which is not the case). So, I am eliminating them from the scaler.\n",
    "\n",
    "- To get in more granular location data, in a sucessive iteration I will one-hot encode the counties to pass along to the model\n",
    "\n",
    "- To dive in finer:\n",
    "    - Pull lat lon from the original database and see how many nulls there are\n",
    "    - Convert zip to lat lon\n",
    "    - Use an unsupervised clustering algorithm to create k neighborhoods\n",
    "    - Explore approppriate k for number of obeservations; 3-6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit scaler to training data\n",
    "\n",
    "scaler = sklearn.preprocessing.RobustScaler()\n",
    "\n",
    "columns = ['bedrooms', 'bathrooms', 'square_feet',  'age']\n",
    "\n",
    "scaler.fit(X_train[columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7224e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaler to all data\n",
    "\n",
    "new_column_names = [c + '_scaled' for c in columns]\n",
    "\n",
    "X_train = pd.concat([X_train, pd.DataFrame(scaler.transform(X_train[columns]), columns=new_column_names, index = train.index),], axis=1)\n",
    "\n",
    "X_validate = pd.concat([X_validate, pd.DataFrame(scaler.transform(X_validate[columns]), columns=new_column_names, index = validate.index),], axis=1)\n",
    "\n",
    "X_test = pd.concat([X_test, pd.DataFrame(scaler.transform(X_test[columns]), columns=new_column_names, index = test.index),], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb181ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce635c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf80987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualize scaler\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(X_train.square_feet, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(X_train.square_feet_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualize scaler\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(X_train.bedrooms, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(X_train.bedrooms_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualize scaler\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(X_train.bathrooms, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(X_train.bathrooms_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3431b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualize scaler\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(X_train.age, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.subplot(122)\n",
    "plt.hist(X_train.age_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c83274",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc5743",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b66f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Combine all of the above steps into function(s)#################\n",
    "\n",
    "#################### IMPORT LIBRARIES #################\n",
    "\n",
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "#Vizualization Tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Modeling Tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Custim functions\n",
    "from env import host, user, password #Database credentials\n",
    "import zillo_wrangle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################ PULL DATA FROM DB ############## \n",
    "\n",
    "def get_db_url(db_name):\n",
    "    return f\"mysql+pymysql://{user}:{password}@{host}/{db_name}\"\n",
    "\n",
    "\n",
    "def get_data_from_sql():\n",
    "    query = \"\"\"\n",
    "    SELECT bedroomcnt as bedrooms, \n",
    "       bathroomcnt as bathrooms,\n",
    "       calculatedfinishedsquarefeet as square_feet,\n",
    "       yearbuilt as year,\n",
    "       taxamount as taxes,\n",
    "       taxvaluedollarcnt as home_value,\n",
    "       fips as fips,\n",
    "       regionidzip as zip_code\n",
    "    FROM predictions_2017\n",
    "     JOIN properties_2017 USING(parcelid)\n",
    "    WHERE (transactiondate >= '2017-01-01' AND transactiondate <= '2017-12-31') \n",
    "        AND propertylandusetypeid = '261'\n",
    "        AND bedroomcnt > 0\n",
    "        AND bathroomcnt > 0\n",
    "        AND calculatedfinishedsquarefeet > 0 \n",
    "        AND taxamount > 0\n",
    "        AND taxvaluedollarcnt > 0\n",
    "        AND fips > 0\n",
    "    ORDER BY fips;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, get_db_url('zillow'))\n",
    "    return df\n",
    "\n",
    "\n",
    "################ REMOVE OUTLIERS #################\n",
    "\n",
    "def remove_outliers(df, k, col_list):\n",
    "    ''' remove outliers from a list of columns in a dataframe \n",
    "        and return that dataframe\n",
    "    '''\n",
    "    \n",
    "    for col in col_list:\n",
    "\n",
    "        q1, q3 = df[col].quantile([.25, .75])  # get quartiles\n",
    "        \n",
    "        iqr = q3 - q1   # calculate interquartile range\n",
    "        \n",
    "        upper_bound = q3 + k * iqr   # get upper bound\n",
    "        lower_bound = q1 - k * iqr   # get lower bound\n",
    "\n",
    "        # return dataframe without outliers\n",
    "        \n",
    "        df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "        \n",
    "    return df\n",
    "\n",
    "######## Clean Data ###########\n",
    "\n",
    "def clean_data(df):\n",
    "    '''\n",
    "    This funciton takes in the zillow df and drops  Null values reassigns some dtypes.\n",
    "    '''\n",
    "    df = df.dropna()\n",
    "    df['fips'] = df['fips'].astype(int)\n",
    "    df['zip_code'] = df['zip_code'].astype(int)\n",
    "    df['square_feet'] = df['square_feet'].astype('int')\n",
    "    df['year'] = df['year'].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "######### ADD COUNTY AND STATE COLUMNS #######\n",
    "\n",
    "def assign_county(row):\n",
    "    if row['fips']==6037:\n",
    "        return 'Los Angeles'\n",
    "    if row['fips']==6059:\n",
    "        return 'Orange'\n",
    "    if row['fips']==6111:\n",
    "        return 'Ventura'\n",
    "\n",
    "######## Feature engineering ########\n",
    "\n",
    "def engineer(zillow):\n",
    "    zillow['county'] = zillow.apply(lambda row: assign_county(row), axis =1) #Add counties\n",
    "    zillow['state'] = 'CA' #Add state\n",
    "    zillow['age'] = date.today().year-zillow.year # Add age\n",
    "    dummy_df = pd.get_dummies(zillow[['county']], drop_first=True)\n",
    "    zillow = pd.concat([zillow, dummy_df], axis=1)\n",
    "    return zillow\n",
    "\n",
    "###### ADD COUNTY AVERAGE #############\n",
    "\n",
    "def county_avg(zillow):\n",
    "    la = zillow[zillow.county=='Los Angeles']\n",
    "    oc = zillow[zillow.county=='Orange']\n",
    "    ven = zillow[zillow.county=='Ventura']\n",
    "\n",
    "    la_avg = la.home_value.mean()\n",
    "    oc_avg = oc.home_value.mean()\n",
    "    ven_avg = ven.home_value.mean()\n",
    "\n",
    "    def assign_county_avg(row):\n",
    "        if row['fips']==6037:\n",
    "            return la_avg\n",
    "        if row['fips']==6059:\n",
    "            return oc_avg\n",
    "        if row['fips']==6111:\n",
    "            return ven_avg\n",
    "\n",
    "    zillow['county_avg'] = zillow.apply(lambda row: assign_county_avg(row), axis =1)\n",
    "\n",
    "    return zillow\n",
    "\n",
    "########## TRAIN VALIDATE TEST SPLIT #########\n",
    "\n",
    "def split_my_data(df, pct=0.10):\n",
    "    '''\n",
    "    This splits a dataframe into train, validate, and test sets. \n",
    "    df = dataframe to split\n",
    "    pct = size of the test set, 1/2 of size of the validate set\n",
    "    Returns three dataframes (train, validate, test)\n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=pct, random_state = 123)\n",
    "    train, validate = train_test_split(train_validate, test_size=pct*2, random_state = 123)\n",
    "    return train, validate, test\n",
    "\n",
    "########## ADD BASELINE #########\n",
    "\n",
    "def add_baseline(train, validate, test):\n",
    "    baseline = train.home_value.median()\n",
    "    train['baseline'] = baseline\n",
    "    validate['baseline'] = baseline\n",
    "    test['baseline'] = baseline\n",
    "    return train, validate, test\n",
    "\n",
    "######## SPLIT IN TO X /y features / target ########\n",
    "\n",
    "def split_xy(train, validate, test):\n",
    "    X_train = train.drop(columns='home_value')\n",
    "    y_train = train.home_value\n",
    "\n",
    "    X_validate = validate.drop(columns='home_value')\n",
    "    y_validate = validate.home_value\n",
    "\n",
    "    X_test = test.drop(columns='home_value')\n",
    "    y_test = test.home_value\n",
    "\n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "\n",
    "############## Robust Scale ###############\n",
    "\n",
    "def scale(X_train, X_validate, X_test, train, validate, test):\n",
    "    scaler = sklearn.preprocessing.RobustScaler()\n",
    "\n",
    "    columns = ['bedrooms', 'bathrooms', 'square_feet', 'fips', 'age', 'zip_code']\n",
    "    \n",
    "    scaler.fit(X_train[columns])\n",
    "\n",
    "    new_column_names = [c + '_scaled' for c in columns]\n",
    "\n",
    "    X_train = pd.concat([X_train, pd.DataFrame(scaler.transform(X_train[columns]), columns=new_column_names, index = train.index),], axis=1)\n",
    "\n",
    "    X_validate = pd.concat([X_validate, pd.DataFrame(scaler.transform(X_validate[columns]), columns=new_column_names, index = validate.index),], axis=1)\n",
    "\n",
    "    X_test = pd.concat([X_test, pd.DataFrame(scaler.transform(X_test[columns]), columns=new_column_names, index = test.index),], axis=1)\n",
    "    \n",
    "    return X_train, X_validate, X_test\n",
    "\n",
    "######### CALL ALL FUNCTIONS TOGETHER #######\n",
    "\n",
    "def wrangle():\n",
    "    zillow = get_data_from_sql()\n",
    "    zillow = remove_outliers(zillow, 1.5, ['bedrooms', 'bathrooms', 'square_feet', 'taxes', 'home_value'])\n",
    "    zillow = clean_data(zillow) #Drop NAs and change dtypes\n",
    "    zillow = engineer(zillow)\n",
    "    zillow = county_avg(zillow)\n",
    "    train, validate, test = split_my_data(zillow)\n",
    "    train, validate, test = add_baseline(train, validate, test)\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = split_xy(train, validate, test)\n",
    "    X_train, X_validate, X_test = scale(X_train, X_validate, X_test, train, validate, test)\n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ea62f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f61b0",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de5a5e",
   "metadata": {},
   "source": [
    "### Initial questions:\n",
    "\n",
    "1. What are drivers of tax value?\n",
    "2. What leads to lower tax values?\n",
    "3. What factors do not impact tax value?\n",
    "4. Is there a difference in average price by county\n",
    "5. Are there any ways to combine the current data into interesting engineered features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34de80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at distribution of all numeric columns in df\n",
    "\n",
    "df.hist(grid=False, figsize=(16,12));\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd352e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63699248",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['bedrooms', 'bathrooms', 'square_feet', 'age', 'home_value']\n",
    "sns.heatmap(df[columns].corr(), cmap='Blues', annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83784605",
   "metadata": {},
   "source": [
    "### Initial impressions\n",
    "\n",
    "- Looking at factors that impact home value, Square footage seems to be the highest driver, followed by bathrooms, then bedrooms\n",
    "\n",
    "- There is a negative correlation with age\n",
    "\n",
    "- Bedrooms matter least out of these sparse columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb33626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a45ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_exploration(df, x_string, y_string):\n",
    "    r, p = stats.pearsonr(df[x_string], df[y_string])\n",
    "    ax= sns.regplot(x=x_string, y=y_string, data=df, line_kws={\"color\": \"red\"})\n",
    "    plt.title(f\"{x_string}'s Relationship with {y_string}\")\n",
    "    print(f'The p-value is: {p}. There is {round(p,3)}% chance that we see these results by chance.')\n",
    "    print(f'r = {round(r, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_exploration(df, 'square_feet', 'home_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_exploration(df, 'bathrooms', 'home_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_exploration(df, 'bedrooms', 'home_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_exploration(df, 'age', 'home_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebc7a3",
   "metadata": {},
   "source": [
    "- [x]Add lines of best fit to scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544e217",
   "metadata": {},
   "source": [
    "Statistical tests confirm, strongest correlation with area, followed by bathrooms, then bedrooms with age being negatively corrolated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fada50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='square_feet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf247ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, y='bedrooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, y='bathrooms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6cf8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ed9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['zip_code']=df['zip_code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='zip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda47e7",
   "metadata": {},
   "source": [
    "weird scaling issues - play arond more if you really care to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea8a85",
   "metadata": {},
   "source": [
    "Is there a difference in home prices by county?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a separate dataframe for each county\n",
    "\n",
    "la = train[train.county=='Los Angeles'].home_value\n",
    "oc = train[train.county=='Orange'].home_value\n",
    "ven = train[train.county=='Ventura'].home_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd824fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize prices by county\n",
    "\n",
    "ax = sns.boxplot(x=train.county, y=train.home_value)\n",
    "#ax = sns.swarmplot(x=train.county, y=train.home_value, color ='.25')\n",
    "plt.title('Figure 5: Average value by County')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755351e",
   "metadata": {},
   "source": [
    "- Perform Kruskal-Wallis H-test to see if there is a difference by county.\n",
    "\n",
    "- Using a nonparametric test since the underlying distributions are not normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kruskal(la, oc, ven)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5adc733",
   "metadata": {},
   "source": [
    "- There are differences by county. \n",
    "\n",
    "- Post-hoc, pairwaise analysis can determine which samples are different in which direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cca7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is LA lower than OC\n",
    "stats.mannwhitneyu(la, oc, alternative ='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73ca5d",
   "metadata": {},
   "source": [
    "- Los Angeles County prices are lower, on average, than Orange County "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49463e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is LA lower than Ventura\n",
    "\n",
    "stats.mannwhitneyu(la, ven, alternative ='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec106254",
   "metadata": {},
   "source": [
    "- Los Angeles County prices are lower, on average, than Ventura County "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d82057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is Ventura Lower than Orange\n",
    "\n",
    "stats.mannwhitneyu(ven, oc, alternative ='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f642f",
   "metadata": {},
   "source": [
    "Ventura is not statistically lower than orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a difference between Ventura and orange\n",
    "\n",
    "stats.mannwhitneyu(ven, oc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cfc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kruskal(oc, ven)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9bd162",
   "metadata": {},
   "source": [
    "There is no statistically significant difference between the mean home values in Orange and Ventura Counties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05be543",
   "metadata": {},
   "source": [
    "### Ideas for final figures:\n",
    "\n",
    "- Figure 1 - Distributions: Panels with distributions of all target varibles\n",
    "- Figure 2 - Drivers: panels with correlations and R/p labelled\n",
    "- Figure 3 - Redce (age)\n",
    "- Figure 4 - Don't matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac79b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='home_value', hue='bedrooms', palette='husl', alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908145b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='home_value', hue='bathrooms', palette='husl', alpha = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08655277",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873bcc9",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Data is now clean split, and scaled and we have a baseline and a feel for meaningful drivers. Proceed with creating MVP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72058709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Import ols\n",
    "\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "\n",
    "ols_model = ols(formula='home_value ~ bedrooms + bathrooms + square_feet', data=train).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7fcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "ols_yhat = ols_model.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['mvp_prdictions']=ols_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebab724",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6bd74",
   "metadata": {},
   "source": [
    "### Evaluate model\n",
    "\n",
    "- RMSE and R^2 will be primary evaluation metrics\n",
    "- Make a dataframe with actual values, baseline predictions, and model predictions\n",
    "- Calculate RMSE\n",
    "- Calculate R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b781e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DataFrame for evaluating model \n",
    "\n",
    "ols_eval = y_train.copy()\n",
    "validate_eval = y_validate.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddf8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_eval = pd.DataFrame(ols_eval)\n",
    "validate_eval = pd.DataFrame(validate_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_eval.rename(columns={'home_value': 'actual'}, inplace=True)\n",
    "validate_eval.rename(columns={'home_value': 'actual'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add baseline - median home value\n",
    "\n",
    "ols_eval['baseline_yhat'] = ols_eval['actual'].median()\n",
    "\n",
    "validate_eval['baseline_yhat'] = ols_eval['actual'].median()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model prediction\n",
    "\n",
    "ols_eval['ols_yhat'] = ols_model.predict(X_train)\n",
    "validate_eval['ols_yhat'] = ols_model.predict(X_validate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9226d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and Add Residuals Column for Plotting\n",
    "\n",
    "ols_eval['residuals'] = ols_eval.ols_yhat - ols_eval.actual\n",
    "validate_eval['residuals'] = validate_eval.ols_yhat - validate_eval.actual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401807ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Compute the RMSE  and R2 for  ols model and baseline \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "baseline_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.baseline_yhat)))\n",
    "ols_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols_yhat)))\n",
    "pct_change=round(((ols_RMSE-baseline_RMSE)/baseline_RMSE)*100, 2)\n",
    "rmse_validate = round(sqrt(mean_squared_error(validate_eval.actual, validate_eval.ols_yhat)))\n",
    "baseline_r2 = round(r2_score(ols_eval.actual, ols_eval.baseline_yhat), 2)\n",
    "ols_train_r2 = round(r2_score(ols_eval.actual, ols_eval.ols_yhat), 2)\n",
    "ols_validate_r2 = round(r2_score(validate_eval.actual, validate_eval.ols_yhat), 2)\n",
    "\n",
    "print(f'My model has value: {ols_RMSE < baseline_RMSE}')\n",
    "print()\n",
    "print(f'Baseline RMSE: {baseline_RMSE}')\n",
    "print(f'My model train RMSE: {ols_RMSE}')\n",
    "print(f'My model validate RMSE: {rmse_validate}')\n",
    "print(f'RMSE difference baseline to model: {baseline_RMSE- ols_RMSE}')\n",
    "print(f'RMSE difference train to validate: {ols_RMSE- rmse_validate}')\n",
    "print(f'RMSE improvement: {pct_change}%')\n",
    "print()\n",
    "print(f'Baseline R2: {baseline_r2}')\n",
    "print(f'Model train  R2: {ols_train_r2}')\n",
    "print(f'Model Validate R2: {ols_validate_r2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fb76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at risiduals distribution\n",
    "\n",
    "plt.hist(np.log(ols_eval.residuals));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cabe7c",
   "metadata": {},
   "source": [
    "Definitley a skew to the residuals - not centered around 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb75229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Predictions vs Residuals\n",
    "\n",
    "plt.scatter(ols_eval.ols_yhat, ols_eval.residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae34c9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c36d7",
   "metadata": {},
   "source": [
    "Next model: same as before, but add age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c029b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3ad87",
   "metadata": {},
   "source": [
    "## OLS2: add age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ea780",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols2_model = ols(formula='home_value ~ bedrooms + bathrooms + square_feet + age',  data=train).fit() #Create model\n",
    "ols2_yhat = ols2_model.predict(X_train) # Make predictions\n",
    "X_train['model2']=ols2_yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to eval\n",
    "ols_eval['ols2_yhat'] = ols2_model.predict(X_train)\n",
    "validate_eval['ols2_yhat'] = ols2_model.predict(X_validate)\n",
    "ols_eval['ols2_residuals'] = ols_eval.ols2_yhat - ols_eval.actual\n",
    "validate_eval['ols2_residuals'] = validate_eval.ols2_yhat - validate_eval.actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedac0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.baseline_yhat)))\n",
    "ols_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols_yhat)))\n",
    "ols2_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols2_yhat)))\n",
    "pct_change_baseline=round(((ols_RMSE-baseline_RMSE)/baseline_RMSE)*100, 2)\n",
    "pct_change_last_model=round(((ols2_RMSE-ols_RMSE)/ols_RMSE)*100, 2)\n",
    "rmse_validate = round(sqrt(mean_squared_error(validate_eval.actual, validate_eval.ols2_yhat)))\n",
    "baseline_r2 = round(r2_score(ols_eval.actual, ols_eval.baseline_yhat), 2)\n",
    "ols2_train_r2 = round(r2_score(ols_eval.actual, ols_eval.ols2_yhat), 2)\n",
    "ols2_validate_r2 = round(r2_score(validate_eval.actual, validate_eval.ols2_yhat), 2)\n",
    "\n",
    "\n",
    "print(f'My model has value: {ols_RMSE < baseline_RMSE}')\n",
    "print(f'My model beats previous model: {ols2_RMSE < ols_RMSE}')\n",
    "print()\n",
    "print(f'Baseline RMSE: {baseline_RMSE}')\n",
    "print(f'Model 1 RMSE: {ols_RMSE}')\n",
    "print(f'Currennt model train RMSE: {ols2_RMSE}')\n",
    "print(f'Currennt model validate RMSE: {rmse_validate}')\n",
    "print()\n",
    "print(f'Current model RMSE difference from baseline: {baseline_RMSE- ols_RMSE}')\n",
    "print(f'RMSE difference train to validate: {ols2_RMSE- rmse_validate}')\n",
    "print(f'Current model baseline RMSE improvement: {pct_change_baseline}%')\n",
    "print(f'Current model RMSE improvement from last model: {pct_change_last_model}%')\n",
    "print()\n",
    "print(f'Baseline R2: {baseline_r2}')\n",
    "print(f'Model train  R2: {ols2_train_r2}')\n",
    "print(f'Model Validate R2: {ols2_validate_r2}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63078066",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at risiduals distribution\n",
    "\n",
    "plt.hist(np.log(ols_eval.ols2_residuals));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aaad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Predictions vs Residuals\n",
    "\n",
    "plt.scatter(ols_eval.ols_yhat, ols_eval.ols2_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols2_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550fb339",
   "metadata": {},
   "source": [
    "### Model 3: add county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols3_model = ols(formula='home_value ~ bedrooms + bathrooms + square_feet + age + county_Orange + county_Ventura',  data=train).fit() #Create model\n",
    "ols3_yhat = ols3_model.predict(X_train) # Make predictions\n",
    "X_train['model3']=ols3_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ded39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_eval['ols3_yhat'] = ols3_model.predict(X_train)\n",
    "ols_eval['ols3_residuals'] = ols_eval.ols3_yhat - ols_eval.actual\n",
    "validate_eval['ols3_yhat'] = ols3_model.predict(X_validate)\n",
    "validate_eval['ols3_residuals'] = validate_eval.ols3_yhat - validate_eval.actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60163ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb661a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.baseline_yhat)))\n",
    "ols_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols_yhat)))\n",
    "ols2_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols2_yhat)))\n",
    "ols3_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols3_yhat)))\n",
    "\n",
    "pct_change_baseline=round(((ols3_RMSE-baseline_RMSE)/baseline_RMSE)*100, 2)\n",
    "pct_change_last_model=round(((ols3_RMSE-ols2_RMSE)/ols2_RMSE)*100, 2)\n",
    "\n",
    "ols3_train_r2 = round(r2_score(ols_eval.actual, ols_eval.ols3_yhat), 2)\n",
    "ols3_validate_r2 = round(r2_score(validate_eval.actual, validate_eval.ols3_yhat), 2)\n",
    "\n",
    "print(f'My model has value: {ols3_RMSE < baseline_RMSE}')\n",
    "print(f'My model beats previous model: {ols3_RMSE < ols2_RMSE}')\n",
    "print()\n",
    "print(f'Baseline RMSE: {baseline_RMSE}')\n",
    "print(f'Model 1 RMSE: {ols_RMSE}')\n",
    "print(f'Model 2 RMSE: {ols2_RMSE}')\n",
    "print(f'Current model RMSE: {ols3_RMSE}')\n",
    "print()\n",
    "print(f'Current model RMSE difference from baseline: {baseline_RMSE- ols3_RMSE}')\n",
    "print(f'Current model baseline RMSE improvement: {pct_change_baseline}%')\n",
    "print(f'Current model RMSE improvement from last model: {pct_change_last_model}%')\n",
    "print()\n",
    "print(f'Baseline R2: {baseline_r2}')\n",
    "print(f'Current Model train  R2: {ols3_train_r2}')\n",
    "print(f'Current Model Validate R2: {ols3_validate_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at risiduals distribution\n",
    "\n",
    "plt.hist(np.log(ols_eval.ols3_residuals));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Predictions vs Residuals\n",
    "\n",
    "plt.scatter(ols_eval.ols_yhat, ols_eval.ols3_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols3_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60687f67",
   "metadata": {},
   "source": [
    "RMSD went down firther and R^2 increased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf10dd",
   "metadata": {},
   "source": [
    "[] Add RMSE for validate on model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0e97b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3c3c1d",
   "metadata": {},
   "source": [
    "### Takeaways / Feature Engineering\n",
    "\n",
    "- MVP model beats baseline\n",
    "- Now, try to beat model\n",
    "- How? Feature engineering\n",
    "- Potential features:\n",
    "    - Incorporate location:\n",
    "        - One-hot encoded counties for now\n",
    "        - Future iterations: Cluster lat/lon for more granular location detail\n",
    "    - Add boolean columns:\n",
    "        - Garage / no garage\n",
    "        - Pool / no pool\n",
    "        - Etc.\n",
    "    - Room score: some kind of single value incorporating both the bedrooms and bathrooms\n",
    "        - Maybe multiplied / weighted by their correlation coefficients\n",
    "    - Stratify columns:\n",
    "        - Age: historical, new constuction, in between"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b4d30",
   "metadata": {},
   "source": [
    "- Build new, select * query to bring in more fields to use for engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9aad6a",
   "metadata": {},
   "source": [
    "### EVALUATION VIZUALS\n",
    "\n",
    "- [] Better actual vs predicted plots\n",
    "    - For a small enough sample of values you can see them\n",
    "- []Residual plots\n",
    "- [] Histograms of actual vs predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f008755c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5e0ca",
   "metadata": {},
   "source": [
    "### LASSO / LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5142d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70589110",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =['bedrooms_scaled', 'bathrooms_scaled','square_feet_scaled', 'age_scaled', 'county_Orange', 'county_Ventura']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2657680",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lasso_lars = lars.fit(X_train[columns], y_train.home_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['lars_predict']=lars.predict(X_train[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92166d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = sqrt(mean_squared_error(y_train.home_value, y_train.lars_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359142ca",
   "metadata": {},
   "source": [
    "Basely worse than model 3 above by RMSE, check R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff09656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d106841",
   "metadata": {},
   "outputs": [],
   "source": [
    "lars_r2 =r2_score(y_train.home_value, y_train.lars_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lars_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7b1c7",
   "metadata": {},
   "source": [
    "# TO DO \n",
    "\n",
    "- [X] Add R2 to printed summaries\n",
    "- [] Hard Code Datafram of models with rmse and r2 for easy, side-by-side comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb384cb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cde0b1",
   "metadata": {},
   "source": [
    "Using a separate wrangle file to feature engineer a more robust model beyond my MVP without breaking anything in that,\n",
    "\n",
    "### Plan:\n",
    "1. Use the same query - change only scalers\n",
    "    -  Linear & Standard\n",
    "    - See if it improves model\n",
    "2. Import all the fields from the database, clean them up, and use K-best for modeling\n",
    "    - Rename columns\n",
    "    - Drop Columns\n",
    "    - Engineer columns\n",
    "    - Encode columns\n",
    "    - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb967c34",
   "metadata": {},
   "source": [
    "## Min-Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b428ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import z_wrangle2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mm, X_train_mm, y_train_mm, X_validate_mm, y_validate_mm, X_test_mm, y_test_mm = z_wrangle2.wrangle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a05325",
   "metadata": {},
   "source": [
    "Test this on current best performing model and compare to current performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model and predictions\n",
    "ols3_model = ols(formula='home_value ~ bedrooms + bathrooms + square_feet + age + county_Orange + county_Ventura',  data=train).fit() #Create model\n",
    "ols3_yhat_mm = ols3_model.predict(X_train_mm) # Make predictions\n",
    "X_train['model3_mm']=ols3_yhat\n",
    "ols_eval['ols3_yhat_mm'] = ols3_model.predict(X_train_mm)\n",
    "ols_eval['ols3_residuals_mm'] = ols_eval.ols3_yhat_mm - ols_eval.actual\n",
    "validate_eval['ols3_yhat_mm'] = ols3_model.predict(X_validate_mm)\n",
    "validate_eval['ols3_residuals_mm'] = validate_eval.ols3_yhat_mm - validate_eval.actual\n",
    "# Calculate evaluation metrics\n",
    "baseline_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.baseline_yhat)))\n",
    "ols_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols_yhat)))\n",
    "ols2_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols2_yhat)))\n",
    "ols3_RMSE = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols3_yhat)))\n",
    "ols3_RMSE_mm = round(sqrt(mean_squared_error(ols_eval.actual, ols_eval.ols3_yhat_mm)))\n",
    "\n",
    "\n",
    "pct_change_baseline=round(((ols3_RMSE_mm-baseline_RMSE)/baseline_RMSE)*100, 2)\n",
    "pct_change_last_model=round(((ols3_RMSE_mm-ols3_RMSE)/ols3_RMSE)*100, 2)\n",
    "\n",
    "ols3_train_r2_mm = round(r2_score(ols_eval.actual, ols_eval.ols3_yhat_mm), 2)\n",
    "ols3_validate_r2_mm = round(r2_score(validate_eval.actual, validate_eval.ols3_yhat_mm), 2)\n",
    "# Display findings\n",
    "print(f'My model has value: {ols3_RMSE_mm < baseline_RMSE}')\n",
    "print(f'My model beats previous model: {ols3_RMSE_mm < ols3_RMSE}')\n",
    "print()\n",
    "print(f'Baseline RMSE: {baseline_RMSE}')\n",
    "print(f'Model 1 RMSE: {ols_RMSE}')\n",
    "print(f'Model 2 RMSE: {ols2_RMSE}')\n",
    "print(f'Model 3 RMSE: {ols3_RMSE}')\n",
    "print(f'Current model RMSE: {ols3_RMSE_mm}')\n",
    "print()\n",
    "print(f'Current model RMSE difference from baseline: {baseline_RMSE- ols3_RMSE_mm}')\n",
    "print(f'Current model baseline RMSE improvement: {pct_change_baseline}%')\n",
    "print(f'Current model RMSE improvement from last model: {pct_change_last_model}%')\n",
    "print()\n",
    "print(f'Baseline R2: {baseline_r2}')\n",
    "print(f'Current Model train  R2: {ols3_train_r2}')\n",
    "print(f'Current Model Validate R2: {ols3_validate_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e7643c",
   "metadata": {},
   "source": [
    "The robust scaler and min max scaler produced the same results. \n",
    "\n",
    "[ ] If time, Try again with standard scaler. For now, go to full database pull snd feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769a821c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9bbd5a",
   "metadata": {},
   "source": [
    "Before doing the heavy-lifting feature engineering\n",
    "\n",
    "- [] first try a polynomial model \n",
    "- [] Tweedie\n",
    "    - power 0, 1, (1,2), 2, 3\n",
    "- [] Re-run the Lasso with different $\\alpha$ values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833debad",
   "metadata": {},
   "source": [
    "## Polynomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8944c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, X_train, y_train, X_validate, y_validate, X_test, y_test = zillo_wrangle.wrangle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7515f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5b4d3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "82c9a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['bedrooms', 'bathrooms', 'square_feet', 'age']\n",
    "\n",
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train[columns])\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate[columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cd063ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8c27abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr_df=pd.DataFrame(X_train_degree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fdf79ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=True)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_degree2, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "383d13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "54fd9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict train\n",
    "y_train['pred_lm2'] = lm2.predict(X_train_degree2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2c6f26fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.home_value, y_train.pred_lm2)**(1/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "56db48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validate=pd.DataFrame(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "53c86451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Polynomial Model, degrees=2\n",
      "Training/In-Sample:  208460.062284777 \n",
      "Validation/Out-of-Sample:  210321.137540738\n",
      "Model Validate R2: 0.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict validate\n",
    "y_validate['pred_lm2'] = lm2.predict(X_validate_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.home_value, y_validate.pred_lm2)**(1/2)\n",
    "\n",
    "lm2_validate_r2 = round(r2_score(y_validate.home_value, y_validate.pred_lm2), 2)\n",
    "\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)\n",
    "\n",
    "print(f'Model Validate R2: {lm2_validate_r2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d865c",
   "metadata": {},
   "source": [
    "Similar R2, but higher RMSE than best current model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e0e93",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "305ae899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dea49de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweedieRegressor(alpha=0, power=1)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "columns=['bedrooms', 'bathrooms', 'square_feet', 'age', 'county_Orange', 'county_Ventura']\n",
    "# fit the model to our training data. \n",
    "glm.fit(X_train[columns], y_train.home_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e12e1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for GLM using Tweedie, power=1 & alpha=0\n",
      "Training/In-Sample:  232947.9993309968 \n",
      "Validation/Out-of-Sample:  234612.5224126042\n",
      "Current Model train  R2: 0.0\n",
      "Current Model Validate R2: -0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict train\n",
    "y_train['pred_glm'] = glm.predict(X_train[columns])\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.home_value, y_train.pred_glm)**(1/2)\n",
    "\n",
    "glm_train_r2 = round(r2_score(y_train.home_value, y_train.pred_glm), 2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['pred_glm'] = glm.predict(X_validate[columns])\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.home_value, y_validate.pred_glm)**(1/2)\n",
    "\n",
    "# Evaluate R2\n",
    "\n",
    "glm_validate_r2 = round(r2_score(y_validate.home_value, y_validate.pred_glm), 2)\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)\n",
    "\n",
    "print(f'Current Model train  R2: {glm_train_r2}')\n",
    "print(f'Current Model Validate R2: {glm_validate_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252b57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c0b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0882bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58d6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980ca5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da587aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb31295b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af557a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a select * from the database and engineer features from there\n",
    "import z_wrangle3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58274e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = z_wrangle3.get_data_from_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3558e3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>id</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "      <th>id</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>fireplaceflag</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11659079</td>\n",
       "      <td>76319</td>\n",
       "      <td>0.107525</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>586346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112370.0</td>\n",
       "      <td>200780.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>88410.0</td>\n",
       "      <td>2618.99</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.037262e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10914401</td>\n",
       "      <td>76320</td>\n",
       "      <td>0.023874</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>1508459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141931.0</td>\n",
       "      <td>709658.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>567727.0</td>\n",
       "      <td>8663.29</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.037144e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11211557</td>\n",
       "      <td>76324</td>\n",
       "      <td>-0.005895</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>1076736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110241.0</td>\n",
       "      <td>137827.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>27586.0</td>\n",
       "      <td>2602.30</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.037911e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11662195</td>\n",
       "      <td>76325</td>\n",
       "      <td>0.142955</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>1719982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108779.0</td>\n",
       "      <td>1631733.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1522954.0</td>\n",
       "      <td>19587.90</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.037263e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12149213</td>\n",
       "      <td>76326</td>\n",
       "      <td>0.066862</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>2720173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296521.0</td>\n",
       "      <td>862405.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>565884.0</td>\n",
       "      <td>9604.06</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.037300e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid     id  logerror transactiondate       id  airconditioningtypeid  \\\n",
       "0  11659079  76319  0.107525      2017-09-13   586346                    NaN   \n",
       "1  10914401  76320  0.023874      2017-09-13  1508459                    NaN   \n",
       "2  11211557  76324 -0.005895      2017-09-13  1076736                    1.0   \n",
       "3  11662195  76325  0.142955      2017-09-13  1719982                    NaN   \n",
       "4  12149213  76326  0.066862      2017-09-13  2720173                    NaN   \n",
       "\n",
       "   architecturalstyletypeid  basementsqft  bathroomcnt  bedroomcnt  ...  \\\n",
       "0                       NaN           NaN          3.0         5.0  ...   \n",
       "1                       NaN           NaN          2.0         2.0  ...   \n",
       "2                       NaN           NaN          2.0         3.0  ...   \n",
       "3                       NaN           NaN          3.0         3.0  ...   \n",
       "4                       NaN           NaN          2.0         3.0  ...   \n",
       "\n",
       "  numberofstories  fireplaceflag  structuretaxvaluedollarcnt  \\\n",
       "0             NaN            NaN                    112370.0   \n",
       "1             NaN            NaN                    141931.0   \n",
       "2             NaN            NaN                    110241.0   \n",
       "3             NaN            NaN                    108779.0   \n",
       "4             NaN            NaN                    296521.0   \n",
       "\n",
       "   taxvaluedollarcnt  assessmentyear  landtaxvaluedollarcnt  taxamount  \\\n",
       "0           200780.0          2016.0                88410.0    2618.99   \n",
       "1           709658.0          2016.0               567727.0    8663.29   \n",
       "2           137827.0          2016.0                27586.0    2602.30   \n",
       "3          1631733.0          2016.0              1522954.0   19587.90   \n",
       "4           862405.0          2016.0               565884.0    9604.06   \n",
       "\n",
       "  taxdelinquencyflag taxdelinquencyyear  censustractandblock  \n",
       "0               None                NaN         6.037262e+13  \n",
       "1               None                NaN         6.037144e+13  \n",
       "2               None                NaN         6.037911e+13  \n",
       "3               None                NaN         6.037263e+13  \n",
       "4               None                NaN         6.037300e+13  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zillow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fde1f9",
   "metadata": {},
   "source": [
    "Get NA counts to see what columns are usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f12a0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52275 entries, 0 to 52274\n",
      "Data columns (total 62 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   parcelid                      52275 non-null  int64  \n",
      " 1   id                            52275 non-null  int64  \n",
      " 2   logerror                      52275 non-null  float64\n",
      " 3   transactiondate               52275 non-null  object \n",
      " 4   id                            52275 non-null  int64  \n",
      " 5   airconditioningtypeid         13628 non-null  float64\n",
      " 6   architecturalstyletypeid      70 non-null     float64\n",
      " 7   basementsqft                  47 non-null     float64\n",
      " 8   bathroomcnt                   52275 non-null  float64\n",
      " 9   bedroomcnt                    52275 non-null  float64\n",
      " 10  buildingclasstypeid           0 non-null      object \n",
      " 11  buildingqualitytypeid         33709 non-null  float64\n",
      " 12  calculatedbathnbr             52260 non-null  float64\n",
      " 13  decktypeid                    387 non-null    float64\n",
      " 14  finishedfloor1squarefeet      4364 non-null   float64\n",
      " 15  calculatedfinishedsquarefeet  52275 non-null  float64\n",
      " 16  finishedsquarefeet12          52117 non-null  float64\n",
      " 17  finishedsquarefeet13          0 non-null      object \n",
      " 18  finishedsquarefeet15          0 non-null      object \n",
      " 19  finishedsquarefeet50          4364 non-null   float64\n",
      " 20  finishedsquarefeet6           158 non-null    float64\n",
      " 21  fips                          52275 non-null  float64\n",
      " 22  fireplacecnt                  7228 non-null   float64\n",
      " 23  fullbathcnt                   52260 non-null  float64\n",
      " 24  garagecarcnt                  17995 non-null  float64\n",
      " 25  garagetotalsqft               17995 non-null  float64\n",
      " 26  hashottuborspa                1515 non-null   float64\n",
      " 27  heatingorsystemtypeid         33904 non-null  float64\n",
      " 28  latitude                      52275 non-null  float64\n",
      " 29  longitude                     52275 non-null  float64\n",
      " 30  lotsizesquarefeet             51919 non-null  float64\n",
      " 31  poolcnt                       11080 non-null  float64\n",
      " 32  poolsizesum                   862 non-null    float64\n",
      " 33  pooltypeid10                  444 non-null    float64\n",
      " 34  pooltypeid2                   1071 non-null   float64\n",
      " 35  pooltypeid7                   9993 non-null   float64\n",
      " 36  propertycountylandusecode     52275 non-null  object \n",
      " 37  propertylandusetypeid         52275 non-null  float64\n",
      " 38  propertyzoningdesc            33771 non-null  object \n",
      " 39  rawcensustractandblock        52275 non-null  float64\n",
      " 40  regionidcity                  51246 non-null  float64\n",
      " 41  regionidcounty                52275 non-null  float64\n",
      " 42  regionidneighborhood          18972 non-null  float64\n",
      " 43  regionidzip                   52252 non-null  float64\n",
      " 44  roomcnt                       52275 non-null  float64\n",
      " 45  storytypeid                   47 non-null     float64\n",
      " 46  threequarterbathnbr           6722 non-null   float64\n",
      " 47  typeconstructiontypeid        76 non-null     float64\n",
      " 48  unitcnt                       33799 non-null  float64\n",
      " 49  yardbuildingsqft17            1927 non-null   float64\n",
      " 50  yardbuildingsqft26            63 non-null     float64\n",
      " 51  yearbuilt                     52242 non-null  float64\n",
      " 52  numberofstories               14534 non-null  float64\n",
      " 53  fireplaceflag                 81 non-null     float64\n",
      " 54  structuretaxvaluedollarcnt    52203 non-null  float64\n",
      " 55  taxvaluedollarcnt             52275 non-null  float64\n",
      " 56  assessmentyear                52275 non-null  float64\n",
      " 57  landtaxvaluedollarcnt         52275 non-null  float64\n",
      " 58  taxamount                     52275 non-null  float64\n",
      " 59  taxdelinquencyflag            2071 non-null   object \n",
      " 60  taxdelinquencyyear            2071 non-null   float64\n",
      " 61  censustractandblock           52161 non-null  float64\n",
      "dtypes: float64(52), int64(3), object(7)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "zillow.info(null_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d2ab905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parcelid                     0\n",
       "id                           0\n",
       "logerror                     0\n",
       "transactiondate              0\n",
       "id                           0\n",
       "                         ...  \n",
       "landtaxvaluedollarcnt        0\n",
       "taxamount                    0\n",
       "taxdelinquencyflag       50204\n",
       "taxdelinquencyyear       50204\n",
       "censustractandblock        114\n",
       "Length: 62, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null1 = zillow.isnull().sum()\n",
    "null1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parcelid                   int64\n",
       "id                         int64\n",
       "logerror                 float64\n",
       "transactiondate           object\n",
       "id                         int64\n",
       "                          ...   \n",
       "landtaxvaluedollarcnt    float64\n",
       "taxamount                float64\n",
       "taxdelinquencyflag        object\n",
       "taxdelinquencyyear       float64\n",
       "censustractandblock      float64\n",
       "Length: 62, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zillow.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f7346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
